{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan_rate_3.txt\n",
      "scan_rate_3.txt: completed\n",
      "scan_rate_2.txt\n",
      "scan_rate_2.txt: completed\n",
      "scan_rate_1.txt\n",
      "scan_rate_1.txt: completed\n",
      "scan_rate_5.txt\n",
      "scan_rate_5.txt: completed\n",
      "scan_rate_4.txt\n",
      "scan_rate_4.txt: completed\n",
      "scan_rate_6.txt\n",
      "scan_rate_6.txt: completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os, math, sklearn.metrics as skm, seaborn as sns, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# This cell can be used to calculate statistics\n",
    "# related to object detection and classification\n",
    "\n",
    "# add some basic info necessary for calculations\n",
    "\n",
    "with open('./useful_dicts/file_to_nearest_neighbor.pkl', 'rb') as f:\n",
    "    file_to_nn = pickle.load(f)\n",
    "\n",
    "with open('./useful_dicts/file_to_scaling.pkl', 'rb') as f:\n",
    "    file_to_scaling = pickle.load(f)\n",
    "\n",
    "def add_info(df, path_obj):\n",
    "    if os.path.isfile(f'./{root}/rich_data/{path_obj.name[:-4]}_corrected.csv'):\n",
    "        return pd.read_csv(f'./{root}/rich_data/{path_obj.name[:-4]}_corrected.csv')\n",
    "    \n",
    "    def IoU(df):\n",
    "        right_i = df[['rgt', 'rpd']].min(axis=1)\n",
    "        left_i = df[['lgt', 'lpd']].max(axis=1)\n",
    "\n",
    "        right_u = df[['rgt', 'rpd']].max(axis=1)\n",
    "        left_u = df[['lgt', 'lpd']].min(axis=1)\n",
    "        IoU = (right_i - left_i)/(right_u - left_u)\n",
    "        return IoU\n",
    "\n",
    "    # Add in left to right rank for correlation with scalled\n",
    "    # results data with original data\n",
    "    df['rank'] = (df['file'] != df['file'].shift()).cumsum() - 1\n",
    "    df['rank'] = df.groupby('file')['rank'].cumcount()\n",
    "\n",
    "    # Extract predicted class\n",
    "    df['pcls'] = df.iloc[:, 8:17].idxmax(axis=1)\n",
    "    # Counts as a match if predicted class matches true and the data contains a GT Box and Pred Box\n",
    "    df['cls'].fillna('phi', inplace=True)\n",
    "    df['match'] = (df['pcls'] == df['cls'])\n",
    "    \n",
    "    # We are swapping out the term 'bg' for 'phi' AFTER matches picked\n",
    "    bg_mask = df['pcls'] == 'bg'\n",
    "    df.loc[bg_mask, 'pcls'] = 'phi'\n",
    "\n",
    "    # Calculate IoUs\n",
    "    IoU_mask = (df['gt'] == 1) & (df['pcls'] != 'phi')\n",
    "    df.loc[IoU_mask, 'IoU'] = IoU(df)\n",
    "\n",
    "    # Pcls mask\n",
    "    pcls_mask = df['pcls'] != 'phi'\n",
    "    df['pcls_prob'] = float('inf')\n",
    "    df.loc[pcls_mask, 'pcls_prob'] = df[df.columns[8:17]].max(axis=1)\n",
    "\n",
    "    df.to_csv(f'./{root}/rich_data/corrected_{path_obj.name[:-4]}.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# calculate diffusion matrix\n",
    "def confusion_matrix(df, mechs):\n",
    "    # confusion matrix generated only on data with aligning GT and PD boxes\n",
    "    cm = skm.confusion_matrix(df['cls'], df['pcls'], labels=mechs, normalize='true') # normalize='true'\n",
    "    return cm\n",
    "\n",
    "def plot_conf_mat(df, cm, labels, title):\n",
    "    plt.subplots(figsize=(8,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', xticklabels=labels, yticklabels=labels, cmap='viridis')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    tp = len(df.loc[(df['match']) & (df['cls'] != 'phi')])\n",
    "    fn = len(df.loc[(df['gt'] == 0) & (df['pd'] == 0)])\n",
    "    fp1 = len(df.loc[(df['gt'] == 0) & (df['pd'] == 1) & (df['pcls'] != 'phi')])\n",
    "    fp2 = len(df.loc[(df['gt'] == 1) & (df['pd'] == 1) & (df['match'] == False)])\n",
    "    accuracy = tp / (fn + fp1 + fp2 + tp)\n",
    "    plt.title(round(accuracy, 4))\n",
    "    plt.savefig(title, dpi=200)\n",
    "    plt.clf()\n",
    "    #plt.show()\n",
    "\n",
    "# calculates stats related to object detection results\n",
    "def obj_det_stats(df, save=False, path=None, train_noise=0, test_noise=0, scan_rates=6):\n",
    "    stats = {}\n",
    "    stats['predicted_pos'] = len(df.loc[df['pd'] == 1]) # TP, FP\n",
    "    stats['population'] = len(df.loc[df['gt'] == 1]) # total GT bounds\n",
    "    stats['false_neg'] = len(df.loc[(df['gt'] == 1) & (df['pd'] == 0)]) # FN\n",
    "    stats['false_pos'] = len(df.loc[(df['gt'] == 0) & (df['pd'] == 1)])\n",
    "    stats['true_pos'] = len(df.loc[(df['gt'] == 1) & (df['pd'] == 1)]) # TP\n",
    "\n",
    "    # Object Detection Stats\n",
    "    stats['precision'] = stats['true_pos'] / stats['predicted_pos']\n",
    "    stats['recall'] = stats['true_pos'] / stats['population']\n",
    "    stats['f1'] = 2*(stats['precision']*stats['recall'])/(stats['precision'] + stats['recall'])\n",
    "\n",
    "    if save:\n",
    "        od_df = pd.DataFrame(stats.values(), index=stats.keys(), columns=[f'{train_noise}_{test_noise}'])\n",
    "        od_df.to_csv(f'{path}/Object_Detection_Stats_{train_noise}_{test_noise}_{scan_rates}.csv', index=True)\n",
    "    return stats\n",
    "\n",
    "# calculates stats related to classification results \n",
    "def class_stats(df, save=False, path=None, train_noise=0, test_noise=0, scan_rates=6):\n",
    "    # Notes: False positive for classes is only misclassifications, backgrounds dropped\n",
    "    stats = {}\n",
    "    stats['predicted_pos'] = len(df.loc[(df['pd'] == 1)]) # TP, FP\n",
    "    stats['population'] = len(df.loc[df['gt'] == 1]) # total GT bounds\n",
    "    stats['false_neg'] = len(df.loc[(df['gt'] == 1) & (df['pd'] == 0)]) # FN\n",
    "    stats['false_pos'] = len(df.loc[(df['pd'] == 1) & (df['match'] == False)])\n",
    "    stats['true_pos'] = len(df.loc[df['match']]) # Classification corrected TP\n",
    "    stats['OD_matches'] = len(df.loc[(df['gt'] == 1) & (df['pd'] == 1)])\n",
    "\n",
    "    # Classification Stats\n",
    "    stats['overall_precision'] = stats['true_pos'] / stats['predicted_pos']\n",
    "    stats['overall_recall'] = stats['true_pos'] / stats['population']\n",
    "    stats['overall_f1'] = 2*(stats['overall_precision']*stats['overall_recall'])/(stats['overall_precision'] + stats['overall_recall'])\n",
    "\n",
    "    def calc_f1(df, label, val):\n",
    "        lcl = df.loc[df[label] == val]\n",
    "        true_pos = len(lcl.loc[lcl['match']])\n",
    "        pp = len(lcl.loc[(lcl['pd'] == 1)])\n",
    "        pop = len(lcl.loc[lcl['gt'] == 1])\n",
    "        precision = true_pos/pp\n",
    "        recall = true_pos/pop\n",
    "        return 2 * (precision * recall)/(precision + recall)\n",
    "\n",
    "    # Event Count F1s\n",
    "    value_counts = df['file'].value_counts()  # Count the occurrences of each value in the \"file\"\n",
    "    count_column = df['file'].map(value_counts.get)  # Map the count of the desired value to each row\n",
    "    df['count'] = count_column\n",
    "    for i in range(4):\n",
    "        stats[f'f1_{i+1}_event'] = calc_f1(df, 'count', i+1)\n",
    "\n",
    "    # Neighbor Count F1s\n",
    "    df['neighbors'] = 0\n",
    "    df.loc[(df['count'] >= 2) & ((df['rank'] == 0) | (df['rank'] == df['count']-1)), 'neighbors'] = 1\n",
    "    df.loc[(df['count'] > 1) & (df['neighbors'] == 0), 'neighbors'] = 2\n",
    "    for i in range(3):\n",
    "        stats[f'f1_{i}_neighbors'] = calc_f1(df, 'neighbors', i)\n",
    "\n",
    "    # Keeping here to make sure it differs from precision\n",
    "    stats['stats_accuracy'] = stats['true_pos']/(stats['predicted_pos'] + stats['false_neg'])\n",
    "    stats['acc_on_OD_TPs'] = stats['true_pos']/stats['OD_matches']\n",
    "\n",
    "    # IoU\n",
    "    stats['average_IoU'] = np.mean(df.loc[df['match']].IoU)\n",
    "    \n",
    "    # Prediction Confidence\n",
    "    stats['prediction_confidence'] = np.mean(df.loc[df['pcls_prob'] < float('inf'), 'pcls_prob'])\n",
    "    stats['pred_conf_correct'] = np.mean(df.loc[(df['match']) & (df['pcls_prob'] < float('inf')), 'pcls_prob'])\n",
    "    stats['pred_conf_incorrect'] = np.mean(df.loc[(df['match'] == False) & (df['pcls_prob'] < float('inf')), 'pcls_prob'])\n",
    "\n",
    "    # Mech by mech things\n",
    "    mechs = ['E','ECb','ECa','ECE','DISP','SR','T','ECP']\n",
    "    prec_numerator = 0\n",
    "    prec_denominator = 0\n",
    "    rec_numerator = 0\n",
    "    rec_denominator = 0\n",
    "    for mech in mechs:\n",
    "        # Calculate IoU\n",
    "        f = df.loc[(df['cls'] == mech) & (df['match'])].copy()\n",
    "        stats[f'IoU_{mech}'] = np.mean(f['IoU'])\n",
    "\n",
    "        if len(f) == 0:\n",
    "            stats[f'prec_{mech}'] = 0\n",
    "            stats[f'rec_{mech}'] = 0\n",
    "            stats[f'F1_{mech}'] = 0\n",
    "\n",
    "        else:\n",
    "            # Calculate class precisions\n",
    "            f = df.loc[df['pcls'] == mech]\n",
    "            hits = len(f.loc[f['cls'] == mech])\n",
    "            stats[f'prec_{mech}'] = hits/len(f)\n",
    "            prec_numerator += hits\n",
    "            prec_denominator += len(f)\n",
    "\n",
    "            # Calculate class recalls\n",
    "            f = df.loc[df['cls'] == mech]\n",
    "            hits = len(f.loc[f['pcls'] == mech])\n",
    "            stats[f'rec_{mech}'] = hits/len(f) \n",
    "            rec_numerator += hits\n",
    "            rec_denominator += len(f)\n",
    "            \n",
    "            # Calculate class f1\n",
    "            if stats[f'prec_{mech}']+stats[f'rec_{mech}'] == 0:\n",
    "                stats[f'F1_{mech}'] = 0\n",
    "            else:\n",
    "                stats[f'F1_{mech}'] = 2*(stats[f'prec_{mech}']*stats[f'rec_{mech}'])/(stats[f'prec_{mech}']+stats[f'rec_{mech}'])\n",
    "\n",
    "    # these are to double check that overall prec and rec align\n",
    "    stats['overall_prec_2'] = prec_numerator/prec_denominator\n",
    "    stats['overall_rec_2'] = rec_numerator/rec_denominator\n",
    "\n",
    "    if save:\n",
    "        cls_df = pd.DataFrame(stats.values(), index=stats.keys(), columns=[f'{train_noise}_{test_noise}'])\n",
    "        cls_df.to_csv(f'{path}/Overall_Stats_{train_noise}_{test_noise}_{scan_rates}.csv', index=True)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# adds info from og metadata files to results\n",
    "def add_og_info(df):\n",
    "    df['key'] = df.apply(lambda x : x['file'].split('/')[-1][:-4] + str(x['rank']), axis=1)\n",
    "    df['scaling'] = df['key'].map(file_to_scaling.get)\n",
    "    df['closest_redox'] = df['key'].map(file_to_nn.get)\n",
    "    df.drop('key', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "root = '230515_sr_results'\n",
    "\n",
    "for path_obj in os.scandir(f'./{root}/data'):\n",
    "    file_path = path_obj.path\n",
    "    file_name = path_obj.name\n",
    "    print(file_name)\n",
    "    details = file_name.split('_')\n",
    "    # sr = 6\n",
    "    sr = details[-1][:-4]\n",
    "    train_noise = 0.01\n",
    "    test_noise = 0.01\n",
    "    # train_noise = details[-1][:-4]\n",
    "    test_noise = train_noise\n",
    "    full_data = pd.read_csv(file_path)\n",
    "    full_data = add_info(full_data, path_obj)\n",
    "    \n",
    "    # calculate object detection related information\n",
    "    od_stats = obj_det_stats(full_data, save=True, path=f'./{root}/stats', train_noise=train_noise, test_noise=test_noise, scan_rates=sr)\n",
    "    notdetected = full_data.loc[(full_data['gt'] == 1) & (full_data['pd'] == 0)].copy()\n",
    "    notdetected.reset_index(drop=True, inplace=True)\n",
    "    notdetected = add_og_info(notdetected)\n",
    "    notdetected.to_csv(f'./{root}/errs/notdetected_{train_noise}_{test_noise}_{sr}.csv', index=False)\n",
    "\n",
    "    # calculate overall (OD + classification) related information\n",
    "    full_data = full_data.loc[~((full_data['gt'] == 0) & (full_data['pcls'] == 'phi'))]\n",
    "    cls_stats = class_stats(full_data, save=True, path=f'./{root}/stats', train_noise=train_noise, test_noise=test_noise, scan_rates=sr)\n",
    "    misclasses = full_data.loc[(full_data['gt'] == 1) & (full_data['pd'] == 1) & (full_data['pcls'] != full_data['cls'])].copy()\n",
    "    misclasses = misclasses.loc[misclasses['pcls'] != 'phi']\n",
    "    misclasses.reset_index(drop=True, inplace=True)\n",
    "    misclasses = add_og_info(misclasses)\n",
    "    misclasses.to_csv(f'./{root}/errs/misclasses_{train_noise}_{test_noise}_{sr}.csv', index=False)\n",
    "    \n",
    "    print(file_name + ': completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, pickle\n",
    "\n",
    "# Used for general meta data calculations on OG data\n",
    "\n",
    "path = '/Volumes/LaCie/20230310/Reports'\n",
    "file_to_neighbor = {}\n",
    "file_to_scaling = {}\n",
    "for obj in os.scandir(path):\n",
    "   if not obj.name.startswith('info'):\n",
    "      continue\n",
    "   df = pd.read_csv(obj.path)\n",
    "   df['rank'] = (df['File'] != df['File'].shift()).cumsum() - 1\n",
    "   df['rank'] = df.groupby('File')['rank'].cumcount()\n",
    "\n",
    "   # num events (0)    \n",
    "   value_counts = df['File'].value_counts()  \n",
    "   count_column = df['File'].map(value_counts.get)\n",
    "   df['eventcount'] = count_column \n",
    "\n",
    "   # has left neighbor (1)\n",
    "   df['hasleft'] = False\n",
    "   left_mask = df['rank'] > 0\n",
    "   df.loc[left_mask, 'hasleft'] = True\n",
    "\n",
    "   # has right neighbor (2)\n",
    "   df['hasright'] = False\n",
    "   right_mask = df['rank'] < df['eventcount']-1\n",
    "   df.loc[right_mask, 'hasright'] = True\n",
    "\n",
    "   # calculate nearest left (3)\n",
    "   df['leftneighbor'] = float('inf')\n",
    "   df.loc[left_mask, 'leftneighbor'] = df['Merge_Left'] - df['Merge_Right'].shift(1)\n",
    "\n",
    "   # calculate nearest right (4)\n",
    "   df['rightneighbor'] = float('inf')\n",
    "   df.loc[right_mask, 'rightneighbor'] = df['Merge_Left'].shift(-1) - df['Merge_Right']\n",
    "\n",
    "   # calc global min (5)\n",
    "   df['closest_redox'] = df[['leftneighbor', 'rightneighbor']].min(axis=1)\n",
    "   # drop (0-4)\n",
    "   df['key'] = df.apply(lambda x : x['File'] + str(x['rank']), axis=1)\n",
    "   file_to_neighbor.update(df[['key', 'closest_redox']].set_index('key')['closest_redox'].to_dict())\n",
    "   file_to_scaling.update(df[['key', 'Scaling']].set_index('key')['Scaling'].to_dict())\n",
    "\n",
    "with open('file_to_nearest_neighbor.pkl', 'wb') as f:\n",
    "   pickle.dump(file_to_neighbor, f)\n",
    "with open('file_to_scaling.pkl', 'wb') as f:\n",
    "   pickle.dump(file_to_scaling, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, pickle, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "def plot_trends(data, xlabel, ylabel, zlabel, labels, title):\n",
    "   for label in labels:\n",
    "      cur = data.loc[data[zlabel] == label]\n",
    "      cur = cur[[xlabel, ylabel]].set_index(xlabel)[ylabel].to_dict()\n",
    "      cur = sorted(cur.items())\n",
    "      x, y = zip(*cur)\n",
    "      plt.plot(x, y, label=label)\n",
    "   plt.title(f'{ylabel} vs. {xlabel}')\n",
    "   plt.xlabel(xlabel)\n",
    "   plt.ylabel(ylabel)\n",
    "   plt.legend(title=zlabel)\n",
    "   plt.savefig(title)   \n",
    "   plt.clf()\n",
    "\n",
    "def noise_box_plots(type, train_noise, file):\n",
    "   labels = ['scaling', 'closest_redox']\n",
    "   test_noises = [0.0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "   for label in labels:\n",
    "      datas = []\n",
    "      for test_noise in test_noises:\n",
    "         misclasses = pd.read_csv(f'./230505_noise_results/errs/{type}_{train_noise}_{test_noise}_6.csv')\n",
    "         misclasses = misclasses.loc[misclasses[label] < float('inf')]\n",
    "         datas.append(misclasses[label])\n",
    "\n",
    "      plt.boxplot(datas, labels=test_noises, showmeans=True, meanline=True)\n",
    "      plt.title(f'{type} Events versus Test Noise, Train Noise {train_noise}')\n",
    "      plt.ylabel(label)\n",
    "      plt.xlabel('Test Noise')\n",
    "      plt.savefig(f'{file}_{train_noise}_{label}.png', dpi=200) \n",
    "      plt.clf()\n",
    "\n",
    "def sr_box_plots(type, file):\n",
    "   labels = ['scaling', 'closest_redox']\n",
    "   scan_rates = [1,2,3,4,5,6]\n",
    "   for label in labels:\n",
    "      data = []\n",
    "      for sr in scan_rates:\n",
    "         misclasses = pd.read_csv(f'./230505_sr_results/errs/{type}_0.01_0.01_{sr}.csv')\n",
    "         misclasses = misclasses.loc[misclasses[label] < float('inf')]\n",
    "         data.append(misclasses[label])\n",
    "      plt.boxplot(data, labels=scan_rates, showmeans=True, meanline=True)\n",
    "      plt.title(f'{type} Events Scan Rate Count, Train Noise {train_noise}')\n",
    "      plt.ylabel(label)\n",
    "      plt.xlabel('Number Scan Rates')\n",
    "      plt.savefig(f'{file}_{label}.png', dpi=200) \n",
    "      plt.clf()\n",
    "\n",
    "def make_table(data, title):\n",
    "   plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n",
    "   plt.rcParams[\"figure.autolayout\"] = True\n",
    "   fig, axs = plt.subplots(1, 1)\n",
    "   fig.set_figheight(10)\n",
    "   axs.axis('off')\n",
    "   labels = list(data.iloc[:, 0])\n",
    "   vals = list(data.iloc[:, 1])\n",
    "   text = [(l, v) for l, v in zip(labels, vals)]\n",
    "   axs.table(cellText=text, colLabels=['Metric', 'Value'], loc='center')\n",
    "   plt.savefig(title, dpi=150)\n",
    "   plt.clf()\n",
    "\n",
    "def plot_distributions(og_data, data, label, title):\n",
    "   og_data = [d for d in og_data.values() if d < float('inf')]\n",
    "   data = data.loc[data[label] < float('inf')]\n",
    "   fig, ax1 = plt.subplots()\n",
    "   ax1.hist(og_data, bins=10, color='blue', label='errs')\n",
    "   ax2 = ax1.twinx()\n",
    "   ax2.hist(data[label], bins=10, color='red', alpha=0.5, label='all')\n",
    "   fig.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes)\n",
    "   plt.savefig(title)\n",
    "   plt.clf()\n",
    "\n",
    "def do_general(base):\n",
    "   for file in os.scandir(f'{base}/rich_data'):\n",
    "      df = pd.read_csv(file.path)\n",
    "      mechs = ['E','ECb','ECa','ECE','DISP','SR','T','ECP', 'phi']\n",
    "      conf_mat = confusion_matrix(df, mechs)\n",
    "      plot_conf_mat(df, conf_mat, mechs, f'{base}/figures/{file.name[:-4]}.png')\n",
    "      df = df.loc[df['pcls'] != 'phi']\n",
    "      mechs = mechs[:-1]\n",
    "      conf_mat = confusion_matrix(df, mechs)\n",
    "      plot_conf_mat(df, conf_mat, mechs, f'{base}/figures/{file.name[:-4]}_no_phi.png')\n",
    "   for file in os.scandir(f'{base}/stats'):\n",
    "      df = pd.read_csv(file.path)\n",
    "      make_table(df, f'{base}/figures/{file.name[:-4]}_table.png')\n",
    "   with open('./useful_dicts/file_to_nearest_neighbor.pkl', 'rb') as cr:\n",
    "      all_closest_redox = pickle.load(cr)\n",
    "   with open('./useful_dicts/file_to_scaling.pkl', 'rb') as sc:\n",
    "      all_scalings = pickle.load(sc)\n",
    "   for file in os.scandir(f'{base}/errs'):\n",
    "      df = pd.read_csv(file.path)\n",
    "      plot_distributions(all_scalings, df, 'scaling', f'{base}/figures/{file.name[:-4]}_scaling.png')\n",
    "      plot_distributions(all_closest_redox, df, 'closest_redox', f'{base}/figures/{file.name[:-4]}_closest_redox.png')\n",
    "\n",
    "def do_noise(base):\n",
    "   od_vals = []\n",
    "   od_columns = []\n",
    "   cls_vals = []\n",
    "   cls_columns = []\n",
    "   for file in os.scandir(f'{base}/stats'):\n",
    "      df = pd.read_csv(file.path)\n",
    "      details = file.name.split('_')\n",
    "      train_noise = float(details[-3])\n",
    "      test_noise = float(details[-2])\n",
    "      srs = int(details[-1][:-4])\n",
    "      if file.name.startswith('Object'):\n",
    "         df = pd.read_csv(file.path)\n",
    "         if len(od_columns) == 0:\n",
    "            od_columns = df.iloc[:, 0].to_list()\n",
    "            od_columns.extend(['train_noise', 'test_noise', 'scan_rates'])\n",
    "         vals = list(df.iloc[:, 1])\n",
    "         vals.extend([train_noise, test_noise, srs])\n",
    "         od_vals.append(vals)\n",
    "      else:\n",
    "         df = pd.read_csv(file.path)\n",
    "         if len(cls_columns) == 0:\n",
    "            cls_columns = df.iloc[:, 0].to_list()\n",
    "            cls_columns.extend(['train_noise', 'test_noise', 'scan_rates'])\n",
    "         vals = list(df.iloc[:, 1])\n",
    "         vals.extend([train_noise, test_noise, srs])\n",
    "         cls_vals.append(vals)\n",
    "   od_df = pd.DataFrame(od_vals, columns=od_columns)\n",
    "   cls_df = pd.DataFrame(cls_vals, columns=cls_columns)\n",
    "   od_metrics = ['false_neg', 'false_pos', 'f1']\n",
    "   train_noises = [0.0, 0.01, 0.05, 0.1, 0.2]\n",
    "   for metric in od_metrics:\n",
    "      title = f'{base}/figures/{metric}_od.png'\n",
    "      plot_trends(od_df, 'test_noise', metric, 'train_noise', train_noises, title)\n",
    "   cls_metrics = ['overall_f1', 'average_IoU', 'acc_on_OD_TPs', 'prediction_confidence']\n",
    "   for metric in cls_metrics:\n",
    "      title = f'{base}/figures/{metric}_cls.png'\n",
    "      plot_trends(cls_df, 'test_noise', metric, 'train_noise', train_noises, title)\n",
    "   \n",
    "   types = ['misclasses', 'notdetected']\n",
    "   train_noises = [0.01, 0.05]\n",
    "   for type in types:\n",
    "      for train_noise in train_noises:\n",
    "         title = f'{base}/figures/{type}'\n",
    "         noise_box_plots(type, train_noise, title)\n",
    "\n",
    "def do_sr(base):\n",
    "   od_vals = []\n",
    "   od_columns = []\n",
    "   cls_vals = []\n",
    "   cls_columns = []\n",
    "   for file in os.scandir(f'{base}/stats'):\n",
    "      df = pd.read_csv(file.path)\n",
    "      details = file.name.split('_')\n",
    "      train_noise = 0.01\n",
    "      test_noise = 0.01\n",
    "      srs = int(details[-1][:-4])\n",
    "      if file.name.startswith('Object'):\n",
    "         df = pd.read_csv(file.path)\n",
    "         if len(od_columns) == 0:\n",
    "            od_columns = df.iloc[:, 0].to_list()\n",
    "            od_columns.extend(['train_noise', 'test_noise', 'scan_rates'])\n",
    "         vals = list(df.iloc[:, 1])\n",
    "         vals.extend([train_noise, test_noise, srs])\n",
    "         od_vals.append(vals)\n",
    "      else:\n",
    "         df = pd.read_csv(file.path)\n",
    "         if len(cls_columns) == 0:\n",
    "            cls_columns = df.iloc[:, 0].to_list()\n",
    "            cls_columns.extend(['train_noise', 'test_noise', 'scan_rates'])\n",
    "         vals = list(df.iloc[:, 1])\n",
    "         vals.extend([train_noise, test_noise, srs])\n",
    "         cls_vals.append(vals)\n",
    "   od_df = pd.DataFrame(od_vals, columns=od_columns)\n",
    "   cls_df = pd.DataFrame(cls_vals, columns=cls_columns)\n",
    "   od_metrics = ['f1', 'precision', 'recall']\n",
    "   for metric in od_metrics:\n",
    "      title = f'{base}/figures/{metric}_od.png'\n",
    "      plot_trends(od_df, 'scan_rates', metric, 'train_noise', [0.01], title)\n",
    "   cls_metrics = ['overall_f1', 'average_IoU', 'prediction_confidence', 'false_neg', 'false_pos']\n",
    "   for metric in cls_metrics:\n",
    "      title = f'{base}/figures/{metric}_cls.png'\n",
    "      plot_trends(cls_df, 'scan_rates', metric, 'train_noise', [0.01], title)\n",
    "\n",
    "   sr_box_plots('notdetected', f'{base}/figures/notdetected')\n",
    "   sr_box_plots('misclasses', f'{base}/figures/misclasses')\n",
    "\n",
    "for obj in os.scandir(r'./'):\n",
    "   if not obj.name.startswith('23'):\n",
    "      continue\n",
    "\n",
    "   base = obj.path\n",
    "   if not os.path.isdir(f'{base}/figures'):\n",
    "      os.mkdir(f'{base}/figures')\n",
    "   \n",
    "   if 'general' in obj.name:\n",
    "      pass\n",
    "      # do_general(base)\n",
    "\n",
    "   if 'noise' in obj.name:\n",
    "      pass\n",
    "      # do_noise(base)\n",
    "      \n",
    "   if 'sr' in obj.name:\n",
    "      do_sr(base)\n",
    "      # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230310_30000/EC_2035_E_1403_EC_1759_T_50650_153329960_data\n",
      "20230310_80000/SR_2941_E_513_SR_521_EC_2074_223909189_data\n",
      "20230310_15000/EC_442_EC_419_E_10120_T_5003_133735326_data\n",
      "20230310_30000/ECE_3327_E_9177_DISP_812_SR_537_155544437_data\n",
      "20230310_20000/T_3252_E_8136_SR_4608_E_9365_143106806_data\n",
      "20230310_5000/ECP_9917_EC_1046_E_3047_E_2538_120647220_data\n",
      "20230310_70000/E_3004_EC_2331_CE_5281_E_7867_212224192_data\n",
      "20230310_25000/EC_2299_DISP_1374_E_4303_SR_4492_150917804_data\n",
      "20230310_35000/E_11855_DISP_12500_ECE_12870_DISP_9902_160629568_data\n",
      "20230310_70000/E_5695_EC_3029_SR_4284_DISP_5352_212832161_data\n",
      "20230310_5000/SR_3613_ECE_6115_EC_1380_EC_1029_12060265_data\n",
      "20230310_75000/DISP_10781_E_12871_EC_3445_SR_270_214233823_data\n",
      "20230310_20000/ECP_51705_E_6807_DISP_8510_E_1820_141959582_data\n",
      "20230310_10000/EC_2106_ECE_5470_SR_250_EC_2879_131825487_data\n",
      "20230310_5000/E_1470_SR_4909_ECE_10555_EC_3161_122048441_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>gt</th>\n",
       "      <th>lgt</th>\n",
       "      <th>rgt</th>\n",
       "      <th>cls</th>\n",
       "      <th>pd</th>\n",
       "      <th>lpd</th>\n",
       "      <th>rpd</th>\n",
       "      <th>bg</th>\n",
       "      <th>E</th>\n",
       "      <th>...</th>\n",
       "      <th>ECP</th>\n",
       "      <th>DISP</th>\n",
       "      <th>SR</th>\n",
       "      <th>T</th>\n",
       "      <th>noise_mag</th>\n",
       "      <th>rank</th>\n",
       "      <th>pcls</th>\n",
       "      <th>match</th>\n",
       "      <th>IoU</th>\n",
       "      <th>pcls_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230310_10000/ECP_5181_SR_2388_E_11102_124834...</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>ECP</td>\n",
       "      <td>1</td>\n",
       "      <td>38.860275</td>\n",
       "      <td>176.480865</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0</td>\n",
       "      <td>ECP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.988078</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230310_10000/ECP_5181_SR_2388_E_11102_124834...</td>\n",
       "      <td>1</td>\n",
       "      <td>333.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>SR</td>\n",
       "      <td>1</td>\n",
       "      <td>331.668121</td>\n",
       "      <td>475.545807</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>1</td>\n",
       "      <td>SR</td>\n",
       "      <td>True</td>\n",
       "      <td>0.987625</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230310_10000/ECP_5181_SR_2388_E_11102_124834...</td>\n",
       "      <td>1</td>\n",
       "      <td>668.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>667.826843</td>\n",
       "      <td>882.961609</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>2</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230310_5000/ECP_3213_E_5131_CE_1612_12073566...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ECP</td>\n",
       "      <td>1</td>\n",
       "      <td>19.239174</td>\n",
       "      <td>136.436768</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0</td>\n",
       "      <td>ECP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.985729</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230310_5000/ECP_3213_E_5131_CE_1612_12073566...</td>\n",
       "      <td>1</td>\n",
       "      <td>276.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>265.285461</td>\n",
       "      <td>473.615540</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>0.903532</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21246</th>\n",
       "      <td>20230310_45000/ECE_6013_E_3579_EC_1198_SR_3177...</td>\n",
       "      <td>1</td>\n",
       "      <td>526.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>ECb</td>\n",
       "      <td>1</td>\n",
       "      <td>521.102600</td>\n",
       "      <td>671.911560</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>2</td>\n",
       "      <td>ECb</td>\n",
       "      <td>True</td>\n",
       "      <td>0.966959</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21247</th>\n",
       "      <td>20230310_45000/ECE_6013_E_3579_EC_1198_SR_3177...</td>\n",
       "      <td>1</td>\n",
       "      <td>745.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>SR</td>\n",
       "      <td>1</td>\n",
       "      <td>745.793579</td>\n",
       "      <td>841.146362</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>3</td>\n",
       "      <td>SR</td>\n",
       "      <td>True</td>\n",
       "      <td>0.990224</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21248</th>\n",
       "      <td>20230310_80000/ECE_7036_SR_1306_DISP_5902_2216...</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>ECE</td>\n",
       "      <td>1</td>\n",
       "      <td>163.029099</td>\n",
       "      <td>552.245300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>0</td>\n",
       "      <td>ECE</td>\n",
       "      <td>True</td>\n",
       "      <td>0.978890</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21249</th>\n",
       "      <td>20230310_80000/ECE_7036_SR_1306_DISP_5902_2216...</td>\n",
       "      <td>1</td>\n",
       "      <td>632.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>SR</td>\n",
       "      <td>1</td>\n",
       "      <td>632.024719</td>\n",
       "      <td>684.597107</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>1</td>\n",
       "      <td>SR</td>\n",
       "      <td>True</td>\n",
       "      <td>0.991932</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21250</th>\n",
       "      <td>20230310_80000/ECE_7036_SR_1306_DISP_5902_2216...</td>\n",
       "      <td>1</td>\n",
       "      <td>794.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>DISP</td>\n",
       "      <td>1</td>\n",
       "      <td>787.287964</td>\n",
       "      <td>934.382324</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>2</td>\n",
       "      <td>DISP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.951770</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21251 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file  gt    lgt    rgt  \\\n",
       "0      20230310_10000/ECP_5181_SR_2388_E_11102_124834...   1   39.0  178.0   \n",
       "1      20230310_10000/ECP_5181_SR_2388_E_11102_124834...   1  333.0  476.0   \n",
       "2      20230310_10000/ECP_5181_SR_2388_E_11102_124834...   1  668.0  883.0   \n",
       "3      20230310_5000/ECP_3213_E_5131_CE_1612_12073566...   1   19.0  135.0   \n",
       "4      20230310_5000/ECP_3213_E_5131_CE_1612_12073566...   1  276.0  484.0   \n",
       "...                                                  ...  ..    ...    ...   \n",
       "21246  20230310_45000/ECE_6013_E_3579_EC_1198_SR_3177...   1  526.0  672.0   \n",
       "21247  20230310_45000/ECE_6013_E_3579_EC_1198_SR_3177...   1  745.0  841.0   \n",
       "21248  20230310_80000/ECE_7036_SR_1306_DISP_5902_2216...   1  168.0  549.0   \n",
       "21249  20230310_80000/ECE_7036_SR_1306_DISP_5902_2216...   1  632.0  685.0   \n",
       "21250  20230310_80000/ECE_7036_SR_1306_DISP_5902_2216...   1  794.0  934.0   \n",
       "\n",
       "        cls  pd         lpd         rpd     bg      E  ...    ECP   DISP  \\\n",
       "0       ECP   1   38.860275  176.480865  0.001  0.000  ...  0.996  0.000   \n",
       "1        SR   1  331.668121  475.545807  0.002  0.001  ...  0.001  0.001   \n",
       "2         E   1  667.826843  882.961609  0.000  0.992  ...  0.000  0.001   \n",
       "3       ECP   1   19.239174  136.436768  0.002  0.000  ...  0.985  0.001   \n",
       "4         E   1  265.285461  473.615540  0.002  0.991  ...  0.000  0.001   \n",
       "...     ...  ..         ...         ...    ...    ...  ...    ...    ...   \n",
       "21246   ECb   1  521.102600  671.911560  0.090  0.012  ...  0.003  0.140   \n",
       "21247    SR   1  745.793579  841.146362  0.001  0.001  ...  0.001  0.001   \n",
       "21248   ECE   1  163.029099  552.245300  0.000  0.001  ...  0.000  0.001   \n",
       "21249    SR   1  632.024719  684.597107  0.001  0.001  ...  0.000  0.000   \n",
       "21250  DISP   1  787.287964  934.382324  0.001  0.001  ...  0.002  0.879   \n",
       "\n",
       "          SR      T  noise_mag  rank  pcls  match       IoU pcls_prob  \n",
       "0      0.000  0.000   0.006779     0   ECP   True  0.988078     0.996  \n",
       "1      0.994  0.001   0.006779     1    SR   True  0.987625     0.994  \n",
       "2      0.001  0.001   0.006779     2     E   True  0.999017     0.992  \n",
       "3      0.001  0.001   0.005818     0   ECP   True  0.985729     0.985  \n",
       "4      0.001  0.001   0.005818     1     E   True  0.903532     0.991  \n",
       "...      ...    ...        ...   ...   ...    ...       ...       ...  \n",
       "21246  0.002  0.003   0.006441     2   ECb   True  0.966959     0.747  \n",
       "21247  0.994  0.001   0.006441     3    SR   True  0.990224     0.994  \n",
       "21248  0.000  0.001   0.007737     0   ECE   True  0.978890     0.995  \n",
       "21249  0.998  0.000   0.007737     1    SR   True  0.991932     0.998  \n",
       "21250  0.001  0.001   0.007737     2  DISP   True  0.951770     0.879  \n",
       "\n",
       "[21251 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for path_obj in os.scandir('.'):\n",
    "#     if not path_obj.name.endswith('csv'):\n",
    "#         continue\n",
    "#     file_path = path_obj.path\n",
    "#     file_name = path_obj.name\n",
    "#     details = file_name.split('_')\n",
    "#     train_noise = details[2]\n",
    "#     test_noise = details[3][:-4]\n",
    "#     print(file_name)\n",
    "#     if os.path.isfile(f'./230505_noise_results/noise_errs/notdetected_{train_noise}_{test_noise}.csv'):\n",
    "#         continue\n",
    "#     full_data = pd.read_csv(file_path)\n",
    "#     full_data = add_info(full_data, path_obj)\n",
    "#     od_stats = obj_det_stats(full_data)\n",
    "#     cls_stats = class_stats(full_data, file_name)\n",
    "#     od_df = pd.DataFrame(od_stats.values(), index=od_stats.keys(), columns=[f'{train_noise}_{test_noise}'])\n",
    "#     od_df.to_csv(f'./230505_noise_results/noise_stats/Object_Detection_Stats_{train_noise}_{test_noise}.csv', index=True)\n",
    "#     cls_df = pd.DataFrame(cls_stats.values(), index=cls_stats.keys(), columns=[f'{train_noise}_{test_noise}'])\n",
    "#     cls_df.to_csv(f'./230505_noise_results/noise_stats/Overall_Stats_{train_noise}_{test_noise}.csv', index=True)\n",
    "#     with open('file_to_meta.pkl', 'rb') as f:\n",
    "#         file_to_meta = pickle.load(f) \n",
    "#     # note: background dropped from full_data at this point\n",
    "#     misclasses = full_data.loc[(full_data['gt'] == 1) & (full_data['pd'] == 1) & (full_data['pcls'] != full_data['cls'])].copy()\n",
    "#     misclasses.reset_index(drop=True, inplace=True)\n",
    "#     notdetected = full_data.loc[(full_data['gt'] == 1) & (full_data['pd'] == 0)].copy()\n",
    "#     notdetected.reset_index(drop=True, inplace=True)\n",
    "#     misclasses = add_og_info(misclasses)\n",
    "#     notdetected = add_og_info(notdetected)\n",
    "#     notdetected.to_csv(f'./230505_noise_results/noise_errs/notdetected_{train_noise}_{test_noise}.csv', index=False)\n",
    "#     misclasses.to_csv(f'./230505_noise_results/noise_errs/misclasses_{train_noise}_{test_noise}.csv', index=False)\n",
    "#     print(file_name + ': completed')\n",
    "\n",
    "# noise = 0.1\n",
    "# big_df = pd.DataFrame()\n",
    "# for obj in os.scandir('./230505_noise_results/rich_data'):\n",
    "    # details = obj.name.split('_')\n",
    "    # train_noise = details[2]\n",
    "    # test_noise = details[3]\n",
    "    # if float(train_noise) != noise or float(test_noise) > noise:\n",
    "    #     continue\n",
    "    # data = pd.read_csv(obj.path)\n",
    "    # data.loc[data['gt'] == 0, 'cls'] = 'phi'\n",
    "    # data.loc[data['pcls'] == 'FN', 'pcls'] = 'phi'\n",
    "    # data['noise'] = test_noise\n",
    "    # big_df = pd.concat([big_df, data])\n",
    "# conf_mat, labels = confusion_matrix(big_df)\n",
    "# plot_conf_mat(big_df, conf_mat, labels, f'{noise}_results_confmat.png')\n",
    "import pandas as pd, matplotlib.pyplot as plt, pickle, numpy as np, os\n",
    "import matplotlib.patches as mpatches\n",
    "df = pd.read_csv('./230510_general_results/data/result_noise_final_0.01.txt')\n",
    "files = list(df['file'])\n",
    "indexes = {5:1, 7:2, 9:3, 11:4}\n",
    "all_files = [set() for _ in range(4)]\n",
    "for file in files:\n",
    "    count = len(file.split('_'))\n",
    "    all_files[indexes[count]-1].add(file)\n",
    "\n",
    "samples = []\n",
    "for subset in all_files:\n",
    "    samples.append([subset.pop() for _ in range(15)])\n",
    "\n",
    "data_path = '/Volumes/LaCie/20230310/Generated_Data'\n",
    "results = pd.read_csv('./230510_general_results/rich_data/result_noise_final_0.01_corrected.csv')\n",
    "for count, lst in enumerate(samples):\n",
    "    if count < 3:\n",
    "        continue\n",
    "    # if not os.path.isdir(f'../Graphs_w_Predictions/{count+1}'):\n",
    "    #     os.mkdir(f'../Graphs_w_Predictions/{count+1}')\n",
    "    if not os.path.isdir(f'../Graphs_w_Predictions/onlygt'):\n",
    "        os.mkdir(f'../Graphs_w_Predictions/onlygt')\n",
    "    for file in lst:\n",
    "        print(file)\n",
    "        with open(f'{data_path}/{file}', 'rb') as f:\n",
    "            raw_data = pickle.load(f)\n",
    "\n",
    "        max_V = raw_data.loc[:, 'V'].max(axis=0)\n",
    "        shrink_factor = 1000/max_V\n",
    "        raw_data['V'] = shrink_factor*raw_data['V']\n",
    "        len_0 = len(results.loc[results['file'] == file])\n",
    "        cur = results.loc[(results['file'] == file) & (results['cls'] != 'phi') & (results['pcls'] != 'phi')]\n",
    "        len_1 = len(cur)\n",
    "        if (len(cur) == 0):\n",
    "            continue\n",
    "        cur.reset_index(inplace=True, drop=True)\n",
    "        noise_mag = set(cur['noise_mag']).pop()\n",
    "        noise = noise_mag*np.random.randn(len(raw_data))\n",
    "        raw_data['A'] += noise\n",
    "\n",
    "        colors = ['#344499' ,'#3A54A1', '#4161AA', '#4474B6', '#4A9AD2', '#42C2EE']\n",
    "        for j, v in enumerate(raw_data['v'].unique()):\n",
    "            t = raw_data.loc[raw_data['v'] == v]\n",
    "            plt.plot(t['V'], t['A'], c=colors[j], linewidth=3)\n",
    "\n",
    "\n",
    "        max_height = raw_data.loc[:, 'A'].max(axis=0)\n",
    "        min_height = raw_data.loc[:, 'A'].min(axis=0)\n",
    "        overall = max_height-min_height\n",
    "\n",
    "        title_parts = []\n",
    "        for i in range(len(cur)):\n",
    "            lcl_chunk = f'{cur.loc[i, \"cls\"]}, {cur.loc[i, \"pcls\"]} {round(100*cur.loc[i, \"pcls_prob\"], 1)}' \n",
    "            title_parts.append(lcl_chunk)\n",
    "            lgt, rgt = cur.loc[i, 'lgt'], cur.loc[i, 'rgt'] \n",
    "            lpd, rpd = cur.loc[i, 'lpd'], cur.loc[i, 'rpd'] \n",
    "            rect=mpatches.Rectangle((lgt,min_height+0.02*overall),(rgt-lgt),0.96*overall, \n",
    "                            fill = False,\n",
    "                            color = \"maroon\",\n",
    "                            linewidth = 2,\n",
    "                            linestyle='dashed',\n",
    "                            zorder=i+10)\n",
    "            plt.gca().add_patch(rect)\n",
    "            rect=mpatches.Rectangle((lpd,min_height+0.02*overall),(rpd-lpd),0.96*overall, \n",
    "                fill = False,\n",
    "                linestyle='dashed',\n",
    "                color = \"red\",\n",
    "                linewidth = 2,\n",
    "                zorder=i+10)\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "        title_parts.append(f'{len_0}_{len_1}')\n",
    "        title = \"–\".join(title_parts)\n",
    "        plt.title(title,fontdict={'size':10})\n",
    "        img_name = file.split('/')[-1][:-4]\n",
    "        plt.savefig(f'../Graphs_w_Predictions/onlygt/{img_name}.png', transparent=True, dpi=600)\n",
    "        #plt.show()\n",
    "        plt.clf()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle, matplotlib.pyplot as plt, numpy.random as rand\n",
    "with open('/Volumes/LaCie/20230310/Generated_Data/20230310_20000/ECP_51705_E_6807_DISP_8510_E_1820_141959582_data', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "noise_levels = [0.0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "fig, ax = plt.subplots(4,2)\n",
    "for i, lvl in enumerate(noise_levels):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    noise = lvl*rand.randn(len(data))\n",
    "    cur = data.copy()\n",
    "    cur['A'] += noise\n",
    "    ax[row, col].scatter(cur['V'], cur['A'], c=cur['v'], s=0.01)\n",
    "    ax[row, col].set_xticks([])\n",
    "    ax[row, col].set_yticks([])\n",
    "    ax[row, col].set_title(f'Noise Level: {lvl}')\n",
    "fig.tight_layout(pad=0)\n",
    "fig.set_figheight(8)\n",
    "plt.savefig(f'./noise_examples/ECP_51705_E_6807_DISP_8510_E_1820_141959582_data_all.png', dpi=300)\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
