{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CE_10869.txt', 'CE_10448.txt', 'CE_1155.txt', 'CE_5578.txt', 'CE_1858.txt', 'CE_3065.txt', 'CE_8419.txt', 'CE_1399.txt', 'CE_12095.txt', 'CE_3788.txt', 'CE_5448.txt']\n",
      "0      CE_9849.txt\n",
      "5     CE_10869.txt\n",
      "6     CE_11342.txt\n",
      "8     CE_12449.txt\n",
      "11     CE_8162.txt\n",
      "12    CE_10934.txt\n",
      "13    CE_11233.txt\n",
      "16    CE_10662.txt\n",
      "18    CE_10448.txt\n",
      "25    CE_10661.txt\n",
      "27     CE_9631.txt\n",
      "29     CE_9962.txt\n",
      "31    CE_11914.txt\n",
      "32     CE_8274.txt\n",
      "34    CE_10822.txt\n",
      "37     CE_8302.txt\n",
      "43    CE_10370.txt\n",
      "44    CE_11293.txt\n",
      "45     CE_8474.txt\n",
      "46    CE_12823.txt\n",
      "52    CE_11075.txt\n",
      "57     CE_8685.txt\n",
      "58     CE_9821.txt\n",
      "66    CE_11462.txt\n",
      "67    CE_10191.txt\n",
      "69     CE_9173.txt\n",
      "72    CE_10757.txt\n",
      "73    CE_11764.txt\n",
      "75     CE_8419.txt\n",
      "77    CE_10916.txt\n",
      "82    CE_10121.txt\n",
      "84    CE_11834.txt\n",
      "86     CE_8427.txt\n",
      "87    CE_12904.txt\n",
      "94    CE_12095.txt\n",
      "99     CE_8151.txt\n",
      "Name: File, dtype: object\n",
      "['CE_10869.txt', 'CE_10448.txt', 'CE_1155.txt', 'CE_5578.txt', 'CE_1858.txt', 'CE_3065.txt', 'CE_8419.txt', 'CE_1399.txt', 'CE_12095.txt', 'CE_3788.txt', 'CE_5448.txt']\n",
      "0      CE_9849.txt\n",
      "5     CE_10869.txt\n",
      "6     CE_11342.txt\n",
      "8     CE_12449.txt\n",
      "11     CE_8162.txt\n",
      "12    CE_10934.txt\n",
      "13    CE_11233.txt\n",
      "16    CE_10662.txt\n",
      "18    CE_10448.txt\n",
      "25    CE_10661.txt\n",
      "27     CE_9631.txt\n",
      "29     CE_9962.txt\n",
      "31    CE_11914.txt\n",
      "32     CE_8274.txt\n",
      "34    CE_10822.txt\n",
      "37     CE_8302.txt\n",
      "43    CE_10370.txt\n",
      "44    CE_11293.txt\n",
      "45     CE_8474.txt\n",
      "46    CE_12823.txt\n",
      "52    CE_11075.txt\n",
      "57     CE_8685.txt\n",
      "58     CE_9821.txt\n",
      "66    CE_11462.txt\n",
      "67    CE_10191.txt\n",
      "69     CE_9173.txt\n",
      "72    CE_10757.txt\n",
      "73    CE_11764.txt\n",
      "75     CE_8419.txt\n",
      "77    CE_10916.txt\n",
      "82    CE_10121.txt\n",
      "84    CE_11834.txt\n",
      "86     CE_8427.txt\n",
      "87    CE_12904.txt\n",
      "94    CE_12095.txt\n",
      "99     CE_8151.txt\n",
      "Name: File, dtype: object\n",
      "['E_3147.txt', 'E_12944.txt', 'E_10981.txt', 'E_2459.txt', 'E_11272.txt', 'E_3759.txt', 'E_1761.txt', 'E_4425.txt', 'E_12450.txt', 'E_5613.txt', 'E_2432.txt', 'E_6513.txt', 'E_1446.txt', 'E_2167.txt', 'E_1876.txt', 'E_11805.txt', 'E_7154.txt', 'E_7008.txt', 'E_9964.txt', 'E_6115.txt', 'E_2415.txt', 'E_4672.txt', 'E_10936.txt', 'E_3684.txt', 'E_11751.txt', 'E_4467.txt', 'E_9962.txt', 'E_8328.txt', 'E_1907.txt', 'E_2064.txt', 'E_7725.txt', 'E_12969.txt', 'E_7297.txt', 'E_9641.txt', 'E_6228.txt', 'E_11440.txt', 'E_6947.txt', 'E_742.txt', 'E_9678.txt', 'E_9446.txt', 'E_1024.txt', 'E_4799.txt', 'E_3961.txt', 'E_12365.txt', 'E_1202.txt', 'E_12553.txt', 'E_11674.txt', 'E_6778.txt', 'E_6750.txt', 'E_12343.txt', 'E_9846.txt', 'E_9852.txt', 'E_25.txt', 'E_6235.txt', 'E_2537.txt', 'E_11461.txt', 'E_6152.txt', 'E_207.txt', 'E_9705.txt', 'E_3410.txt', 'E_991.txt', 'E_9074.txt', 'E_3388.txt', 'E_12620.txt', 'E_9470.txt', 'E_8319.txt', 'E_466.txt', 'E_3919.txt', 'E_1539.txt', 'E_6726.txt', 'E_9401.txt', 'E_5808.txt', 'E_9835.txt', 'E_10525.txt', 'E_12044.txt', 'E_3937.txt', 'E_11148.txt', 'E_3843.txt']\n",
      "0      E_6513.txt\n",
      "1      E_1446.txt\n",
      "2      E_2167.txt\n",
      "3      E_1876.txt\n",
      "4     E_11805.txt\n",
      "         ...     \n",
      "95    E_12044.txt\n",
      "96     E_3937.txt\n",
      "97     E_2432.txt\n",
      "98    E_11148.txt\n",
      "99     E_3843.txt\n",
      "Name: File, Length: 97, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, os, numpy as np, random as r, pickle, math\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Mech:\n",
    "   def __init__(self, mech, cathodic):\n",
    "      self.mech = mech\n",
    "      self.cathodic = cathodic\n",
    "      self.data = None\n",
    "      self.file = None\n",
    "      self.scaling = r.randint(50, 100)/100\n",
    "\n",
    "   def __str__(self):\n",
    "      return f'Mech: {self.mech}, Cathodic: {self.cathodic}, Scaling: {self.scaling}, File: {self.file}'\n",
    "\n",
    "class MergeCV:\n",
    "   def __init__(\n",
    "                  self, \n",
    "                  num_to_merge=4,\n",
    "                  scale_min=0.2, \n",
    "                  forward_current_limit=0.05, \n",
    "                  reverse_current_limit=0.01,\n",
    "                  fractional_peak_current=0.33,\n",
    "                  dictating_scan_rate=0,\n",
    "                  peak_ratio=0.1,\n",
    "                  additional_shift_min=0,\n",
    "                  additional_shift_max=1000,          \n",
    "   ):\n",
    "      self.num_to_merge = num_to_merge\n",
    "      self.scale_min = scale_min\n",
    "      self.forward_current_limit = forward_current_limit\n",
    "      self.reverse_current_limit = reverse_current_limit\n",
    "      self.fractional_peak_current = fractional_peak_current\n",
    "      self.dictating_scan_rate = dictating_scan_rate\n",
    "      self.peak_ratio = peak_ratio\n",
    "      self.additional_shift_min = additional_shift_min\n",
    "      self.additional_shift_max = additional_shift_min \n",
    "      self.name = \"\"\n",
    "      self.mechs = None\n",
    "      self.res = None\n",
    "\n",
    "   def __get_mechs(self):\n",
    "      mechs = [None]*self.num_to_merge\n",
    "      x = r.randint(1, 8)\n",
    "      if x == 1:\n",
    "         cath = round(r.random())\n",
    "         if cath:\n",
    "            mechs[0] = Mech(\"T\", True)\n",
    "         else:\n",
    "            mechs[-1] = Mech(\"T\", False)\n",
    "\n",
    "      x = r.randint(1, 8)\n",
    "      if x == 2:\n",
    "         cath = round(r.random())\n",
    "         if cath and not mechs[0]:\n",
    "            mechs[0] = Mech(\"ECP\", True)\n",
    "         elif cath:\n",
    "            mechs[-1] = Mech(\"ECP\", False)\n",
    "         elif mechs[-1]:\n",
    "            mechs[0] = Mech(\"ECP\", True)\n",
    "         else:\n",
    "            mechs[-1] = Mech(\"ECP\", False)\n",
    "\n",
    "      # EC1 is equal to EC anodic or CE cathodic, EC2 is equal to CE anodic or EC cathodic\n",
    "      remaining_mechs = [\"E\", \"EC1\", \"ECE\", \"DISP\", \"CE\"] # REMOVED SR\n",
    "      for i, spot in enumerate(mechs):\n",
    "         if not spot:\n",
    "            x = r.randint(0, len(remaining_mechs)-1)\n",
    "            cathodic = True if round(r.random()) == 1 else False\n",
    "            mechs[i] = Mech(remaining_mechs[x], cathodic)\n",
    "      self.mechs = mechs\n",
    "   \n",
    "   def __get_valid_file(self, options, mechanism, host_range):\n",
    "      if host_range == 0:\n",
    "         return r.choice(options)\n",
    "      sr_info = pd.read_csv(f'./Scan_Rate_Info/{mechanism}_SRs.csv')\n",
    "      min_sr_range = host_range-0.2\n",
    "      max_sr_range = host_range+0.2\n",
    "      sr_info = sr_info.loc[(sr_info['Range'] >= min_sr_range) & (sr_info['Range'] <= max_sr_range)]\n",
    "      sr_info = sr_info.loc[sr_info['File'].isin(options)]\n",
    "      indices = sr_info.index\n",
    "      return sr_info.loc[r.choice(indices), 'File']  \n",
    "\n",
    "   def __get_files(self):\n",
    "      host_range = 0\n",
    "      for i, mech in enumerate(self.mechs):\n",
    "         # safe means it can be merged from either side, so no special consideration is necessary\n",
    "         safe = pickle.load(open(f'./Merge_Safety/{mech.mech}_safe.pkl', 'rb'))\n",
    "         # half safe means it is useable as a beginning or terminal mechanism so needs to be looked at\n",
    "         half_safe = pickle.load(open(f'./Merge_Safety/{mech.mech}_half_safe.pkl', 'rb'))\n",
    "         if i == 1 or i == 2:\n",
    "            options = list(safe.keys())\n",
    "            file = self.__get_valid_file(options, mech.mech, host_range)\n",
    "         # considerations on if T or ECP need to be flipped have already been made so pick any file\n",
    "         elif mech.mech == 'T' or mech.mech == 'ECP':\n",
    "            options = list(safe.keys())\n",
    "            options.extend(list(half_safe.keys()))\n",
    "            file = self.__get_valid_file(options, mech.mech, host_range)\n",
    "         else:\n",
    "            options = list(safe.keys())\n",
    "            options.extend(list(half_safe.keys()))\n",
    "            file = self.__get_valid_file(options, mech.mech, host_range)\n",
    "            if file not in safe:\n",
    "               # if data is only mergeable from one side, we may need to over-ride the assigned flipping\n",
    "               left_safe = half_safe[file][0]\n",
    "               right_safe = half_safe[file][1]\n",
    "               if left_safe: # must be flipped if it is left most, otherwise can't be\n",
    "                  if i == 0:\n",
    "                     mech.cathodic = True\n",
    "                  else:\n",
    "                     mech.cathodic = False\n",
    "               else: # must be flipped if it right most, otherwise can't be\n",
    "                  if i == 0:\n",
    "                     mech.cathodic = False\n",
    "                  else:\n",
    "                     mech.cathodic = True\n",
    "         mech.file = file\n",
    "         self.name += file[:-4] + \"_\"\n",
    "         mech.data = pd.read_csv(f'./Samples/{mech.mech}/{file}')\n",
    "         if host_range == 0:\n",
    "            host_range = math.log10(max(mech.data['v'])) - math.log10(min(mech.data['v']))\n",
    "         min_V = min(mech.data['V'])\n",
    "         mech.data.loc[:,'V'] -= min_V\n",
    "         mech.data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "   def __adjust_data(self, mech):\n",
    "      flip = -1 if mech.cathodic else 1\n",
    "      mech.data.loc[:, 'A'] *= mech.scaling*flip\n",
    "      res = pd.DataFrame()\n",
    "      if mech.cathodic:\n",
    "         for v in mech.data['v'].unique():\n",
    "            t = mech.data.loc[mech.data['v'] == v].copy()\n",
    "            currents = t.loc[:,'A']\n",
    "            n = len(currents)//2\n",
    "            fwd_currents = list(currents[:n])\n",
    "            rev_currents = list(currents[n:])\n",
    "            rev_currents.extend(fwd_currents)\n",
    "            t['A'] = rev_currents\n",
    "            res = pd.concat([res, t])\n",
    "         mech.data = res\n",
    "      mech.data.reset_index(inplace=True, drop=True)   \n",
    "      \n",
    "   def __calculate_merge_reps(self, mech):\n",
    "\n",
    "      def find_index(l, r, target, data):\n",
    "         decreasing = data.loc[l, 'A'] > data.loc[r, 'A']\n",
    "         while (l <= r):\n",
    "            m = l+(r-l) // 2\n",
    "            if data.loc[m, 'A'] < target:\n",
    "               if decreasing:\n",
    "                  r = m-1\n",
    "               else:\n",
    "                  l = m+1\n",
    "            else:\n",
    "               if decreasing:\n",
    "                  l = m+1\n",
    "               else:\n",
    "                  r = m-1\n",
    "         return l if l <= data.index[-1] else data.index[-1]\n",
    "\n",
    "      scan_rates = mech.data['v'].unique()\n",
    "      rep_data = mech.data[mech.data['v'] == scan_rates[self.dictating_scan_rate]]\n",
    "\n",
    "      max_A = max(rep_data['A'])\n",
    "      min_A = min(rep_data['A'])\n",
    "      \n",
    "      peak_ratio = abs(min_A/max_A) if abs(min_A) < max_A else abs(max_A/min_A)\n",
    "      reversible = peak_ratio >= 0.1\n",
    "      main_peak = max_A if max_A > abs(min_A) else min_A\n",
    "      # Mpi = max peak index, mpi = min peak index\n",
    "      Mpi = rep_data[rep_data['A'] == max_A].index[0]\n",
    "      mpi = rep_data[rep_data['A'] == min_A].index[0]\n",
    "\n",
    "      merge_points = []\n",
    "      indices = rep_data.index\n",
    "      l = indices[0]\n",
    "      r = indices[-1]\n",
    "      n = indices[len(indices)//2]\n",
    "      if rep_data.loc[Mpi, 'A'] == main_peak or reversible:\n",
    "         target = self.fractional_peak_current*(max_A-rep_data.loc[n,'A']) + rep_data.loc[n,'A']\n",
    "         merge_points.append(find_index(l, Mpi, target, rep_data))\n",
    "         merge_points.append(find_index(Mpi, n, target, rep_data))\n",
    "      if rep_data.loc[mpi, 'A'] == main_peak or reversible:\n",
    "         target = rep_data.loc[r,'A'] - self.fractional_peak_current*(abs(min_A-rep_data.loc[r,'A']))\n",
    "         merge_points.append(find_index(n+1,mpi, target, rep_data))\n",
    "         merge_points.append(find_index(mpi, r, target, rep_data))\n",
    "   \n",
    "      mech.data['merge_point'] = False\n",
    "      for point in merge_points:\n",
    "         mech.data.loc[point, 'merge_point'] = True\n",
    "\n",
    "   def initialize_data(self):\n",
    "      mechs = self.__get_mechs()\n",
    "      self.__get_files()\n",
    "      for i, mech in enumerate(self.mechs):\n",
    "         self.__adjust_data(mech)\n",
    "         self.__calculate_merge_reps(mech)\n",
    "\n",
    "   def __calculate_shifts(self):\n",
    "\n",
    "      def get_mps(indices, data):\n",
    "         max_potential = data.loc[indices[0], 'V']\n",
    "         min_potential = max_potential\n",
    "         for i in range(1, len(indices)):\n",
    "            cur = data.loc[indices[i], 'V']\n",
    "            max_potential = max(max_potential, cur)\n",
    "            min_potential = min(min_potential, cur)\n",
    "         return [min_potential, max_potential]\n",
    "\n",
    "      host = self.mechs[0].data\n",
    "      mpis = host.loc[host['merge_point']].index\n",
    "      host_mps = get_mps(mpis, host)\n",
    "      shifts = [0]\n",
    "      for i in range(1, len(self.mechs)):\n",
    "         guest = self.mechs[i].data\n",
    "         mpis = guest.loc[guest['merge_point']].index\n",
    "         guest_mps = get_mps(mpis, guest)\n",
    "         host_pot = host_mps[1]\n",
    "         guest_pot = guest_mps[0]\n",
    "         shift = (host_pot-guest_pot) + r.randint(self.additional_shift_min, self.additional_shift_max)\n",
    "         shifts.append(shift)\n",
    "         guest_mps[1] += shift\n",
    "         host_mps = guest_mps\n",
    "      return shifts\n",
    "\n",
    "   def format_data(self):\n",
    "      shifts = self.__calculate_shifts()\n",
    "      for i, mech in enumerate(self.mechs):\n",
    "         mech.data.loc[:,'V'] += shifts[i]\n",
    "         mapping = {v:i for i,v in enumerate(mech.data['v'].unique())}\n",
    "         mech.data.replace({'v': mapping}, inplace=True)\n",
    "         mech.data.drop(['merge_point'], axis=1, inplace=True)\n",
    "\n",
    "   def __merge_dfs(self, dfs, rev=False):\n",
    "      res = pd.DataFrame()\n",
    "      left_adds = []\n",
    "      right_adds = []\n",
    "      for df in dfs:\n",
    "         if rev:\n",
    "            df = df[::-1]\n",
    "         left_adds.append([min(df['V']), df.loc[df.index[0], 'A']])\n",
    "         right_adds.append([max(df['V']), df.loc[df.index[-1], 'A']])   \n",
    "         if len(res) == 0:\n",
    "            res = df\n",
    "         else:\n",
    "            res = pd.concat([res, df]).groupby(['V','v']).sum().reset_index()\n",
    "      res.drop(['index'], axis=1, inplace=True)\n",
    "      for left in left_adds:\n",
    "         res.loc[res['V'] < left[0], 'A'] += left[1]\n",
    "      for right in right_adds:\n",
    "         res.loc[res['V'] > right[0], 'A'] += right[1]\n",
    "      return res\n",
    "\n",
    "   def merge(self, single=False):\n",
    "      res = pd.DataFrame()\n",
    "      for i in range(6):\n",
    "         fwd_dfs = []\n",
    "         rev_dfs = []\n",
    "         name = \"\"\n",
    "         global_max = 0\n",
    "         for j, mech in enumerate(self.mechs):\n",
    "            if j == 3:\n",
    "               global_max = max(mech.data['V'])\n",
    "            name += mech.file[:-4]\n",
    "            data = mech.data[mech.data['v'] == i].copy()\n",
    "            data.reset_index(inplace=True)\n",
    "            n = data.loc[data['V'] == max(data['V'])].index[0]\n",
    "            fwd_dfs.append(data.iloc[:n, :])\n",
    "            rev_dfs.append(data.iloc[n:, :])\n",
    "         fwd_full = self.__merge_dfs(fwd_dfs)\n",
    "         rev_full = self.__merge_dfs(rev_dfs, rev=True)\n",
    "         rev_full = rev_full[::-1]\n",
    "         res = pd.concat([res, fwd_full, rev_full])\n",
    "         if single:\n",
    "            res = res.loc[(res['V'] > 0) & (res['V'] < global_max)]\n",
    "            res.reset_index(inplace=True, drop=True)\n",
    "            self.res = res\n",
    "            return res # tabbed in for single scan rate\n",
    "      res = res.loc[(res['V'] > 0) & (res['V'] < global_max)]\n",
    "      res.reset_index(inplace=True, drop=True)\n",
    "      self.res = res\n",
    "      return res\n",
    "\n",
    "   def simple_plot(self):\n",
    "      for mech in self.mechs:\n",
    "         data = mech.data\n",
    "         plt.scatter(data['V'], data['A'], s=0.1, c=data['v'], cmap='Set2')\n",
    "         plt.show()\n",
    "         plt.clf()\n",
    "\n",
    "   def fancy_plot(self, save=False, highlight=False):\n",
    "      fig = plt.figure(constrained_layout=True)\n",
    "      gs = GridSpec(4,2, figure=fig,hspace=0, wspace=0)\n",
    "      cmap='viridis'\n",
    "      components = []\n",
    "      components.append(fig.add_subplot(gs[3:4, :1]))\n",
    "      components.append(fig.add_subplot(gs[2:3, :1]))\n",
    "      components.append(fig.add_subplot(gs[3:4, -1:]))\n",
    "      components.append(fig.add_subplot(gs[2:3, -1:]))\n",
    "\n",
    "      ax1 = fig.add_subplot(gs[:2,:])\n",
    "      infos = [[\"Mech\"],[\"Scaling\"],[\"Direction\"]]\n",
    "      name = \"\"\n",
    "      if highlight:\n",
    "         colors=['rebeccapurple', 'dodgerblue', 'cyan', 'black']\n",
    "      else:\n",
    "         colors=['white']*self.num_to_merge\n",
    "      bar_xs = []\n",
    "      bar_widths = []\n",
    "      for i, mech in enumerate(self.mechs):\n",
    "         name += mech.file[:-4] + \"_\"\n",
    "         infos[0].append(mech.mech)\n",
    "         infos[1].append(mech.scaling)\n",
    "         infos[2].append(\"cathodic\" if mech.cathodic else \"anodic\")\n",
    "         ax = components.pop(0)\n",
    "         ax.get_xaxis().set_ticks([])\n",
    "         ax.get_yaxis().set_ticks([])\n",
    "         ax.patch.set_facecolor(colors[i])\n",
    "         ax.patch.set_alpha(0.2)\n",
    "         ax.scatter(mech.data['V'], mech.data['A'], s=0.02, c=mech.data['v'], cmap=cmap)\n",
    "         min_V = max(0, min(mech.data['V']))\n",
    "         max_V = min(max(self.res['V']), max(mech.data['V']))\n",
    "         bar_width = max_V-min_V\n",
    "         bar_xs.append(min_V + bar_width//2)\n",
    "         bar_widths.append(max_V-min_V)\n",
    "\n",
    "      bottom = min(self.res['A'])\n",
    "      y_range =max(self.res['A']) - min(self.res['A'])\n",
    "      bar_heights = [y_range/4]*self.num_to_merge\n",
    "      bottoms = [bottom + i*bar_heights[0] for i in range(4)]\n",
    "      bar_heights = [y_range/4]*self.num_to_merge\n",
    "      ax1.bar(bar_xs, bar_heights, bottom=bottoms, width=bar_widths, color=colors, alpha=0.2, zorder=0)\n",
    "      ax1.scatter(self.res['V'], self.res['A'], s=0.05, c=self.res['v'], cmap=cmap, zorder=1)\n",
    "      ax1.table(infos, loc='top', cellLoc='center')\n",
    "      ax1.tick_params(axis=\"both\", labelsize=8)\n",
    "      if save:\n",
    "         plt.savefig(f'./Graphs/{name}image', dpi=200)\n",
    "      else:\n",
    "         plt.show()\n",
    "      plt.clf()\n",
    "\n",
    "   def save(self):\n",
    "      info = {}\n",
    "      for i, mech in enumerate(self.mechs):\n",
    "         info['Cathodic'] = mech.cathodic\n",
    "         info['Scaling'] = mech.scaling\n",
    "         info['File'] = mech.file\n",
    "         info['Position'] = i\n",
    "      pickle.dump(info, open(f'./Generated_Data/{self.name}details', 'wb'))\n",
    "      pickle.dump(self.res, open(f'./Generated_Data/{self.name}data', 'wb'))\n",
    "\n",
    "for i in tqdm(range(1)): # ~ 100/minute w/ graphing every 25, ≥ 140k per day)\n",
    "   try:\n",
    "      merger = MergeCV()\n",
    "      merger.initialize_data()\n",
    "      merger.format_data()\n",
    "      merger.merge()\n",
    "      if i % 1 == 0:\n",
    "         merger.fancy_plot(save=True, highlight=True)\n",
    "   except:\n",
    "      print(\"oopsie\")\n",
    "   #merger.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechs = ['ECE','E','T','EC1','DISP','EC1','CE']\n",
    "path = './Samples'\n",
    "for mech in mechs:\n",
    "   files = os.listdir(f'{path}/{mech}')\n",
    "   files = [f for f in files if f.endswith('txt')] \n",
    "   info = []\n",
    "   for file in files:\n",
    "      data = pd.read_csv(f'{path}/{mech}/{file}')\n",
    "      range_srs = math.log10(max(data['v'])) - math.log10(min(data['v']))\n",
    "      info.append([file, range_srs])\n",
    "   sr_data = pd.DataFrame(info, columns=['File', 'Range'])\n",
    "   sr_data.to_csv(f'./SR_Info/{mech}_SRs.csv', index=False)\n",
    "sr_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
